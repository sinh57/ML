# ============================================================
# UBER FARE PREDICTION PROJECT
# ============================================================
# AIM:
# Predict the price of the Uber ride from a given pickup point 
# to the drop-off location using ML models.
#
# TASKS:
# 1. Pre-process the dataset
# 2. Identify outliers
# 3. Check correlation
# 4. Implement Linear Regression & Random Forest Regression
# 5. Evaluate models using R2, RMSE, MAE, etc.
# ============================================================




# STEP 1: Import libraries
# ------------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error





# STEP 2: Load the dataset
# ------------------------------------------------------------

df = pd.read_csv(r"C:\Users\lenovo\OneDrive\Documents\ML_codes\1.uber\uber.csv")

print("Initial data shape:", df.shape)
print(df.head())




# STEP 3: Data Cleaning & Pre-processing
# ------------------------------------------------------------
# Drop unnecessary column
if 'Unnamed: 0' in df.columns:
    df = df.drop(columns=['Unnamed: 0'])

# Convert datetime column
df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')

# Remove rows with missing or invalid values
df = df.dropna(subset=['fare_amount', 'pickup_longitude', 'pickup_latitude',
                       'dropoff_longitude', 'dropoff_latitude', 'pickup_datetime'])

# Remove invalid fares and passenger counts
df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 1000)]
df = df[(df['passenger_count'] >= 1) & (df['passenger_count'] <= 6)]




# STEP 4: Feature Engineering â€“ Distance Calculation
# ------------------------------------------------------------
# Function to calculate distance using Haversine formula
def haversine(lon1, lat1, lon2, lat2):
    from math import radians, sin, cos, asin, sqrt
    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))
    return 6371 * c  # in kilometers

# Create new column for distance
df['distance_km'] = df.apply(lambda x: haversine(x['pickup_longitude'], x['pickup_latitude'],
                                                 x['dropoff_longitude'], x['dropoff_latitude']), axis=1)

# Extract datetime features
df['hour'] = df['pickup_datetime'].dt.hour
df['day'] = df['pickup_datetime'].dt.day
df['month'] = df['pickup_datetime'].dt.month
df['year'] = df['pickup_datetime'].dt.year
df['weekday'] = df['pickup_datetime'].dt.weekday

# Keep only useful features
data = df[['fare_amount', 'distance_km', 'passenger_count', 'hour', 'day', 'month', 'year', 'weekday']]




# STEP 5: Identify & Remove Outliers
# ------------------------------------------------------------
# Remove rides with zero or extremely large distances
data = data[(data['distance_km'] > 0) & (data['distance_km'] < 200)]




# STEP 6: Check Correlation
# ------------------------------------------------------------
print("\nCorrelation Matrix:")
print(data.corr())
plt.figure(figsize=(6,5))
plt.title("Correlation Heatmap")
plt.imshow(data.corr(), cmap='coolwarm', interpolation='nearest')
plt.colorbar()
plt.xticks(range(len(data.columns)), data.columns, rotation=45)
plt.yticks(range(len(data.columns)), data.columns)
plt.show()




# STEP 7: Train-Test Split
# ------------------------------------------------------------
X = data[['distance_km', 'passenger_count', 'hour', 'day', 'month', 'year', 'weekday']]
y = data['fare_amount']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("\nTraining size:", X_train.shape, "Test size:", X_test.shape)




# STEP 8: Linear Regression Model
# ------------------------------------------------------------
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)




# STEP 9: Random Forest Regression Model
# ------------------------------------------------------------
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)




# STEP 10: Evaluate Models
# ------------------------------------------------------------
def evaluate(y_true, y_pred, model_name):
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    print(f"\n{model_name} Performance:")
    print(f"R2 Score: {r2:.3f}")
    print(f"RMSE: {rmse:.3f}")
    print(f"MAE: {mae:.3f}")

evaluate(y_test, y_pred_lr, "Linear Regression")
evaluate(y_test, y_pred_rf, "Random Forest")




# STEP 11: Compare Models
# ------------------------------------------------------------
results = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest'],
    'R2 Score': [r2_score(y_test, y_pred_lr), r2_score(y_test, y_pred_rf)],
    'RMSE': [np.sqrt(mean_squared_error(y_test, y_pred_lr)), np.sqrt(mean_squared_error(y_test, y_pred_rf))],
    'MAE': [mean_absolute_error(y_test, y_pred_lr), mean_absolute_error(y_test, y_pred_rf)]
})

print("\nModel Comparison:")
print(results)




# STEP 12: Plot Actual vs Predicted
# ------------------------------------------------------------
plt.figure(figsize=(8,4))
plt.scatter(y_test[:100], y_pred_rf[:100], color='blue', label='Random Forest', alpha=0.6)
plt.scatter(y_test[:100], y_pred_lr[:100], color='red', label='Linear Regression', alpha=0.6)
plt.xlabel("Actual Fare")
plt.ylabel("Predicted Fare")
plt.legend()
plt.title("Actual vs Predicted Fare Comparison")
plt.show()
